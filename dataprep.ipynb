{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597468599502",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values with Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical imputation transform for the horse colic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Missing: 1605\nMissing: 0\n"
    }
   ],
   "source": [
    "# import necssary libraries\n",
    "from numpy import isnan \n",
    "from pandas import read_csv \n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "# load dataset\n",
    "url = 'http://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
    "dataframe = read_csv(url, header=None, na_values='?')\n",
    "\n",
    "# split into input and output\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "\n",
    "# print total missing \n",
    "print(\"Missing: %d\" % sum(isnan(X).flatten()))\n",
    "\n",
    "# define imputer \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# fit on the dataset\n",
    "imputer.fit(X)\n",
    "\n",
    "# transform the dataset\n",
    "Xtrans = imputer.transform(X)\n",
    "\n",
    "# print total missing\n",
    "print(\"Missing: %d\" % sum(isnan(Xtrans).flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features with RFE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report which features were selected by RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Column: 0, Selected=False, Rank:4\nColumn: 1, Selected=False, Rank:5\nColumn: 2, Selected=True, Rank:1\nColumn: 3, Selected=True, Rank:1\nColumn: 4, Selected=True, Rank:1\nColumn: 5, Selected=False, Rank:6\nColumn: 6, Selected=True, Rank:1\nColumn: 7, Selected=False, Rank:3\nColumn: 8, Selected=True, Rank:1\nColumn: 9, Selected=False, Rank:2\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification \n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "\n",
    "# define RFE \n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "\n",
    "# fit RFE\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# summarize all features \n",
    "for i in range(X.shape[1]): \n",
    "    print(\"Column: %d, Selected=%s, Rank:%d\" % (i, rfe.support_[i], rfe.ranking_[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data with Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of normalizing input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1.16445804  2.20489985  0.98705394 -0.24892557  0.02730749 -0.54607659\n  -1.13378169  2.92506351  1.26673358  1.46401078]\n [ 1.07746722 -4.1026129  -0.28684337  2.26184715  0.24576105 -0.00716217\n  -1.10238571 -0.34331894  0.64221845 -1.22448632]\n [ 1.03496179 -1.90438963  0.51909698 -1.79314569 -2.59816732 -1.17865026\n   1.2355152   2.93608911 -0.73405942  1.24542021]]\nAfter Transformation\n[[0.47346034 0.68996947 0.53789567 0.50720087 0.56775645 0.41669053\n  0.31761837 0.7371739  0.62726634 0.71577552]\n [0.46605616 0.1968639  0.4356307  0.79618474 0.58941628 0.48397861\n  0.32153252 0.46146966 0.54828922 0.34243806]\n [0.46243834 0.3687155  0.50032937 0.32946487 0.30743877 0.33770828\n  0.61299983 0.73810396 0.37424304 0.68542099]]\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=10, n_informative=5, n_redundant=0, random_state=1)\n",
    "\n",
    "# summarize data before transform\n",
    "print(X[:3, :])\n",
    "\n",
    "# define the scaler \n",
    "trans = MinMaxScaler()\n",
    "\n",
    "# transform the data\n",
    "X_norm = trans.fit_transform(X)\n",
    "\n",
    "# summarize data after transform \n",
    "print(\"After Transformation\")\n",
    "print(X_norm[:3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Categories with One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encode the breast cancer dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[\"'40-49'\" \"'premeno'\" \"'15-19'\" \"'0-2'\" \"'yes'\" \"'3'\" \"'right'\"\n  \"'left_up'\" \"'no'\"]\n [\"'50-59'\" \"'ge40'\" \"'15-19'\" \"'0-2'\" \"'no'\" \"'1'\" \"'right'\" \"'central'\"\n  \"'no'\"]\n [\"'50-59'\" \"'ge40'\" \"'35-39'\" \"'0-2'\" \"'no'\" \"'2'\" \"'left'\" \"'left_low'\"\n  \"'no'\"]]\n[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]]\n"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# define the location of dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\"\n",
    "\n",
    "# load the dataset\n",
    "dataset = read_csv(url, header=None)\n",
    "\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "\n",
    "# separate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# summarize the raw data \n",
    "print(X[:3, :])\n",
    "\n",
    "# define the one hot encoding transform\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# fit and apply the transform to the input data\n",
    "X_oe = encoder.fit_transform(X)\n",
    "\n",
    "# summarize the transfromed data\n",
    "print(X_oe[:3, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfrom Numbers to Categories with kBins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discretize numeric input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 2.39324489 -5.77732048 -0.59062319 -2.08095322  1.04707034]\n [-0.45820294  1.94683482 -2.46471441  2.36590955 -0.73666725]\n [ 2.35162422 -1.00061698 -0.5946091   1.12531096 -0.65267587]]\nAfter transform\n[[7. 0. 4. 1. 5.]\n [4. 7. 2. 6. 4.]\n [7. 5. 4. 5. 4.]]\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=5, n_redundant=0, random_state=1)\n",
    "\n",
    "# summarize data before the transform\n",
    "print(X[:3, :])\n",
    "\n",
    "# define the transforms\n",
    "trans = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "\n",
    "# transform the data\n",
    "X_discrete = trans.fit_transform(X)\n",
    "\n",
    "# summmarize data after the transforms\n",
    "print(\"After transform\")\n",
    "print(X_discrete[:3, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-0.53448246  0.93837451  0.38969914  0.0926655   1.70876508  1.14351305\n  -1.47034214  0.11857673 -2.72241741  0.2953565 ]\n [-2.42280473 -1.02658758 -2.34792156 -0.82422408  0.59933419 -2.44832253\n   0.39750207  2.0265065   1.83374105  0.72430365]\n [-1.83391794 -1.1946668  -0.73806871  1.50947233  1.78047734  0.58779205\n  -2.78506977 -0.04163788 -1.25227833  0.99373587]]\nAfter the transform\n[[-1.64710578 -2.11683302  1.98256096]\n [ 0.92840209  4.8294997   0.22727043]\n [-3.83677757  0.32300714  0.11512801]]\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# dafine dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=3, n_redundant=7, \n",
    "random_state=1)\n",
    "\n",
    "# summarize data before transforms\n",
    "print(X[:3, :])\n",
    "\n",
    "# define the transforms\n",
    "trans = PCA(n_components=3)\n",
    "\n",
    "# transform the data\n",
    "X_dims = trans.fit_transform(X)\n",
    "\n",
    "# summarize data after transforms\n",
    "print(\"After the transform\")\n",
    "print(X_dims[:3, :])"
   ]
  }
 ]
}